Figures are generated using following scripts:
fig1c,fig1d - data generated by hs_iter_grid_2rooms_formedW.txt 
fig1f,fig2 - data generated by KLs_reg_iter_valiter_grid_formedWCopies.txt 
fig1f,alpha=0&beta=0 - data generated by KLs_R_valiterCopies.txt 
Schematics fig1a,b,e and fig3 are plotted manually

To run a script, one need python installed, and run the command line: 

python filename.txt 

with the respective filename.

Python should be installed before, including following used packages: numpy, cv2, PIL. Also, for generating videos ghostscript should be installed, and the path to the ghostscript exe file (gswin64.exe) should be set to the variable EpsImagePlugin.gs_windows_binary

Simulations were performed on a laptop with a processor Intel Core i7-10750H CPU, 2.6 GHz, 6 Cores, with 32Gb RAM


Parameters of the simulations are just variables in the script files, particularly

N - arena size (so that arena is inside N by N square),
alpha - coefficient alpha in the article text,
bet - coefficient beta in the article text,
nz - the level of noise in action selection for RL learning (epsilon for the epsilon-greedy policy in the main text),
T - number of iteration steps (total number of iteration steps for KLs_reg_iter_valiter_grid_formedWCopies.txt and hs_iter_grid_2rooms_formedW.txt, number of reference policy updates for KLs_R_valiterCopies.txt)
Titer - number of value iteratiomns between two reference policy updates,
r - array with rewards (for KLs_reg_iter_valiter_grid_formedWCopies.txt and KLs_R_valiterCopies.txt),
steps - simulation length for hs_iter_grid_2rooms_formedW.txt.

Arena shape is coded in the array form, 1 in form[0,i,j] is for existance of a field at (i,j) location for the agent. Array w1 codes possible transitions, w1[i,j] is 1 for -possibe transition from location (i//N,i%N) to location (j//N,j%N).
Food amount at (i,j) is given by food[i,j] in the N by N array food, in considered cases just filled with 1.   


Prefixes of some files containing data generated by scripts:
for KLs_reg_iter_valiter_grid_formedWCopies.txt,KLs_R_valiterCopies.txt
Reward per timestep - in "rev_av..." there is an array with reward per timestep for values of alpha varying over first axis and beta over the second one, minimal and maximal values of those are written in the filename.

for hs_iter_grid_2rooms_formedW.txt
Occupancy averaged over simulation time - in "occ_..." there is an N by N array with number of visits of a location (i,j) written at the array element (i,j).
Trajectory - in "rec_"+pref+"_steps"+str(steps) there is one-dimentional array with a state s (here in the form i*N^3+j*N^2) at timestep t written at the array element t.